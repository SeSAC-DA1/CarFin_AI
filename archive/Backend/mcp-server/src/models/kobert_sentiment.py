"""
ì‹¤ì œ KoBERT ê¸°ë°˜ í•œêµ­ì–´ ê°ì •ë¶„ì„ ëª¨ë¸
Korean Sentiment Analysis using KoBERT
"""

import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel
import numpy as np
from typing import List, Dict, Any, Tuple
import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor
import os

logger = logging.getLogger("KoBERT-Sentiment")

class KoBERTSentimentClassifier(nn.Module):
    """KoBERT ê¸°ë°˜ ê°ì •ë¶„ì„ ë¶„ë¥˜ê¸°"""

    def __init__(self, n_classes=3, dropout=0.1):
        super().__init__()
        self.kobert = AutoModel.from_pretrained('monologg/kobert')
        self.dropout = nn.Dropout(dropout)
        self.classifier = nn.Linear(768, n_classes)  # ê¸ì •, ì¤‘ë¦½, ë¶€ì •

    def forward(self, input_ids, attention_mask):
        outputs = self.kobert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output
        output = self.dropout(pooled_output)
        return self.classifier(output)

class RealKoBERTSentimentAnalyzer:
    """ì‹¤ì œ KoBERT ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°ì •ë¶„ì„ê¸°"""

    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.tokenizer = None
        self.model = None
        self.max_length = 512
        self.executor = ThreadPoolExecutor(max_workers=4)

        # ê°ì • ë ˆì´ë¸” ë§¤í•‘
        self.sentiment_labels = {
            0: 'negative',   # ë¶€ì •
            1: 'neutral',    # ì¤‘ë¦½
            2: 'positive'    # ê¸ì •
        }

        logger.info(f"ğŸ¤– KoBERT ê°ì •ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹œì‘ (Device: {self.device})")

    async def initialize(self):
        """ëª¨ë¸ ì´ˆê¸°í™” (ë¹„ë™ê¸°)"""
        try:
            # KoBERT í† í¬ë‚˜ì´ì € ë¡œë“œ
            self.tokenizer = AutoTokenizer.from_pretrained('monologg/kobert', trust_remote_code=True)

            # ëª¨ë¸ ë¡œë“œ
            self.model = KoBERTSentimentClassifier(n_classes=3)

            # ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” fine-tuned ëª¨ë¸ ì‚¬ìš©)
            checkpoint_path = os.path.join(os.path.dirname(__file__), 'kobert_sentiment.pth')
            if os.path.exists(checkpoint_path):
                self.model.load_state_dict(torch.load(checkpoint_path, map_location=self.device))
                logger.info("âœ… ì‚¬ì „ í›ˆë ¨ëœ ê°ì •ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ì—†ìŒ, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")

            self.model.to(self.device)
            self.model.eval()

            logger.info("âœ… KoBERT ê°ì •ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ KoBERT ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def _preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        # ê¸°ë³¸ ì •ì œ
        text = text.strip()
        text = text.replace('\n', ' ').replace('\r', ' ')
        text = ' '.join(text.split())  # ì—°ì† ê³µë°± ì œê±°

        return text[:1000]  # ìµœëŒ€ ê¸¸ì´ ì œí•œ

    def _tokenize_text(self, text: str) -> Dict[str, torch.Tensor]:
        """í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•"""
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].to(self.device),
            'attention_mask': encoding['attention_mask'].to(self.device)
        }

    def _predict_single(self, text: str) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ê°ì • ì˜ˆì¸¡"""
        try:
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            cleaned_text = self._preprocess_text(text)

            # í† í¬ë‚˜ì´ì§•
            inputs = self._tokenize_text(cleaned_text)

            # ì˜ˆì¸¡
            with torch.no_grad():
                outputs = self.model(inputs['input_ids'], inputs['attention_mask'])
                probabilities = torch.nn.functional.softmax(outputs, dim=-1)
                predicted_class = torch.argmax(probabilities, dim=-1).item()
                confidence = probabilities.max().item()

            # ê²°ê³¼ ë°˜í™˜
            sentiment_label = self.sentiment_labels[predicted_class]

            return {
                'text': text[:100] + '...' if len(text) > 100 else text,
                'sentiment': sentiment_label,
                'confidence': float(confidence),
                'probabilities': {
                    'negative': float(probabilities[0][0]),
                    'neutral': float(probabilities[0][1]),
                    'positive': float(probabilities[0][2])
                },
                'score': self._convert_to_score(predicted_class, confidence)
            }

        except Exception as e:
            logger.error(f"âŒ ê°ì •ë¶„ì„ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {
                'text': text[:100] + '...' if len(text) > 100 else text,
                'sentiment': 'neutral',
                'confidence': 0.5,
                'probabilities': {'negative': 0.33, 'neutral': 0.34, 'positive': 0.33},
                'score': 3.0,
                'error': str(e)
            }

    def _convert_to_score(self, predicted_class: int, confidence: float) -> float:
        """ê°ì • í´ë˜ìŠ¤ë¥¼ 1-5 ì ìˆ˜ë¡œ ë³€í™˜"""
        base_scores = {0: 2.0, 1: 3.0, 2: 4.0}  # ë¶€ì •: 2, ì¤‘ë¦½: 3, ê¸ì •: 4
        base_score = base_scores[predicted_class]

        # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì ìˆ˜ ì¡°ì •
        if predicted_class == 0:  # ë¶€ì •
            return max(1.0, base_score - (confidence - 0.5) * 2)
        elif predicted_class == 2:  # ê¸ì •
            return min(5.0, base_score + (confidence - 0.5) * 2)
        else:  # ì¤‘ë¦½
            return base_score

    async def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¹„ë™ê¸° ê°ì •ë¶„ì„"""
        if not self.model:
            await self.initialize()

        # GPU ì—°ì‚°ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            self.executor,
            self._predict_single,
            text
        )

        return result

    async def analyze_multiple_sentiments(self, texts: List[str]) -> List[Dict[str, Any]]:
        """ë‹¤ì¤‘ í…ìŠ¤íŠ¸ ë°°ì¹˜ ê°ì •ë¶„ì„"""
        if not self.model:
            await self.initialize()

        tasks = [self.analyze_sentiment(text) for text in texts]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # ì˜ˆì™¸ ì²˜ë¦¬
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"âŒ í…ìŠ¤íŠ¸ {i} ë¶„ì„ ì‹¤íŒ¨: {result}")
                processed_results.append({
                    'text': texts[i][:100] + '...' if len(texts[i]) > 100 else texts[i],
                    'sentiment': 'neutral',
                    'confidence': 0.5,
                    'probabilities': {'negative': 0.33, 'neutral': 0.34, 'positive': 0.33},
                    'score': 3.0,
                    'error': str(result)
                })
            else:
                processed_results.append(result)

        return processed_results

    def calculate_overall_sentiment(self, individual_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ê°œë³„ ê°ì •ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì „ì²´ ê°ì • ê³„ì‚°"""
        valid_results = [r for r in individual_results if 'error' not in r]

        if not valid_results:
            return {
                'average_score': 3.0,
                'sentiment_distribution': {'negative': 0.33, 'neutral': 0.34, 'positive': 0.33},
                'total_analyzed': 0,
                'confidence': 0.5,
                'dominant_sentiment': 'neutral'
            }

        # í‰ê·  ì ìˆ˜ ê³„ì‚°
        scores = [r['score'] for r in valid_results]
        average_score = np.mean(scores)

        # ê°ì • ë¶„í¬ ê³„ì‚°
        sentiment_counts = {'negative': 0, 'neutral': 0, 'positive': 0}
        confidence_sum = 0

        for result in valid_results:
            sentiment_counts[result['sentiment']] += 1
            confidence_sum += result['confidence']

        total_count = len(valid_results)
        sentiment_distribution = {
            k: v / total_count for k, v in sentiment_counts.items()
        }

        # ì£¼ìš” ê°ì • ê²°ì •
        dominant_sentiment = max(sentiment_distribution, key=sentiment_distribution.get)

        return {
            'average_score': float(average_score),
            'sentiment_distribution': sentiment_distribution,
            'total_analyzed': total_count,
            'confidence': float(confidence_sum / total_count) if total_count > 0 else 0.5,
            'dominant_sentiment': dominant_sentiment,
            'score_std': float(np.std(scores)) if len(scores) > 1 else 0.0
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
kobert_analyzer = RealKoBERTSentimentAnalyzer()

async def analyze_korean_sentiment(text: str) -> Dict[str, Any]:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°ì •ë¶„ì„ API"""
    return await kobert_analyzer.analyze_sentiment(text)

async def analyze_korean_sentiments_batch(texts: List[str]) -> List[Dict[str, Any]]:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë°°ì¹˜ ê°ì •ë¶„ì„ API"""
    return await kobert_analyzer.analyze_multiple_sentiments(texts)