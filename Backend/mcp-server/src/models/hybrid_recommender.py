"""
ì‹¤ì œ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ
Hybrid Recommendation System: Content-based + Collaborative Filtering + Popularity

í•µì‹¬ êµ¬ì„±ìš”ì†Œ:
1. Content-based Filtering: ì°¨ëŸ‰ íŠ¹ì„± ê¸°ë°˜ ì¶”ì²œ
2. Collaborative Filtering: NCF (Neural Collaborative Filtering)
3. Popularity-based Filtering: ì‹œì¥ ì¸ê¸°ë„ ê¸°ë°˜
4. Price Fairness Analysis: ê°€ê²© ì ì •ì„± ë¶„ì„
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Any, Tuple, Optional
import logging
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import TruncatedSVD
import torch
import torch.nn as nn
import torch.optim as optim
from datetime import datetime, timedelta
import asyncio
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger("HybridRecommender")

class NCFModel(nn.Module):
    """Neural Collaborative Filtering ëª¨ë¸"""

    def __init__(self, num_users: int, num_items: int, embedding_dim: int = 32, hidden_dims: List[int] = [64, 32, 16]):
        super().__init__()

        # ì„ë² ë”© ë ˆì´ì–´
        self.user_embedding = nn.Embedding(num_users, embedding_dim)
        self.item_embedding = nn.Embedding(num_items, embedding_dim)

        # MLP ë ˆì´ì–´
        self.mlp_layers = nn.ModuleList()
        input_dim = embedding_dim * 2

        for hidden_dim in hidden_dims:
            self.mlp_layers.append(nn.Linear(input_dim, hidden_dim))
            self.mlp_layers.append(nn.ReLU())
            self.mlp_layers.append(nn.Dropout(0.2))
            input_dim = hidden_dim

        self.output_layer = nn.Linear(hidden_dims[-1], 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, user_ids: torch.Tensor, item_ids: torch.Tensor) -> torch.Tensor:
        user_emb = self.user_embedding(user_ids)
        item_emb = self.item_embedding(item_ids)

        # ì„ë² ë”© ì—°ê²°
        mlp_input = torch.cat([user_emb, item_emb], dim=1)

        # MLP í†µê³¼
        for layer in self.mlp_layers:
            mlp_input = layer(mlp_input)

        output = self.output_layer(mlp_input)
        return self.sigmoid(output)

class ContentBasedRecommender:
    """ë‚´ìš© ê¸°ë°˜ ì¶”ì²œê¸°"""

    def __init__(self):
        self.tfidf_vectorizer = TfidfVectorizer(max_features=1000)
        self.scaler = StandardScaler()
        self.feature_matrix = None
        self.vehicle_features = None

    def fit(self, vehicles_df: pd.DataFrame):
        """ì°¨ëŸ‰ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ"""
        try:
            # í…ìŠ¤íŠ¸ íŠ¹ì„± ë²¡í„°í™” (ë¸Œëœë“œ, ëª¨ë¸, ì—°ë£Œíƒ€ì… ë“±)
            text_features = vehicles_df.apply(
                lambda x: f"{x['brand']} {x['model']} {x.get('fuel_type', '')} {x.get('transmission', '')}",
                axis=1
            )

            text_matrix = self.tfidf_vectorizer.fit_transform(text_features)

            # ìˆ˜ì¹˜ íŠ¹ì„± ì •ê·œí™”
            numeric_features = ['year', 'price', 'mileage']
            numeric_data = vehicles_df[numeric_features].fillna(0)
            numeric_matrix = self.scaler.fit_transform(numeric_data)

            # íŠ¹ì„± ê²°í•©
            self.feature_matrix = np.hstack([
                text_matrix.toarray(),
                numeric_matrix
            ])

            self.vehicle_features = vehicles_df.copy()
            logger.info(f"âœ… Content-based ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: {len(vehicles_df)}ëŒ€ ì°¨ëŸ‰")

        except Exception as e:
            logger.error(f"âŒ Content-based í•™ìŠµ ì‹¤íŒ¨: {e}")
            raise

    def recommend(self, user_profile: Dict[str, Any], top_k: int = 10) -> List[Tuple[int, float]]:
        """ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜ ì¶”ì²œ"""
        try:
            if self.feature_matrix is None:
                raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

            # ì‚¬ìš©ì í”„ë¡œí•„ì„ ë²¡í„°ë¡œ ë³€í™˜
            user_vector = self._create_user_vector(user_profile)

            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = cosine_similarity([user_vector], self.feature_matrix)[0]

            # ìƒìœ„ kê°œ ì¶”ì²œ
            top_indices = np.argsort(similarities)[::-1][:top_k]
            recommendations = [(idx, float(similarities[idx])) for idx in top_indices]

            logger.info(f"âœ… Content-based ì¶”ì²œ ì™„ë£Œ: {len(recommendations)}ê°œ")
            return recommendations

        except Exception as e:
            logger.error(f"âŒ Content-based ì¶”ì²œ ì‹¤íŒ¨: {e}")
            return []

    def _create_user_vector(self, user_profile: Dict[str, Any]) -> np.ndarray:
        """ì‚¬ìš©ì í”„ë¡œí•„ì„ íŠ¹ì„± ë²¡í„°ë¡œ ë³€í™˜"""
        # ì„ í˜¸ ë¸Œëœë“œ/ëª¨ë¸ í…ìŠ¤íŠ¸ ìƒì„±
        preferred_text = f"{user_profile.get('preferred_brands', [''])[0]} {user_profile.get('fuel_type', '')} {user_profile.get('transmission', '')}"

        # í…ìŠ¤íŠ¸ ë²¡í„°í™”
        text_vector = self.tfidf_vectorizer.transform([preferred_text]).toarray()[0]

        # ìˆ˜ì¹˜ íŠ¹ì„± (ì˜ˆì‚° ì¤‘ê°„ê°’, ìµœì‹  ì—°ë„ ì„ í˜¸, ë‚®ì€ ì£¼í–‰ê±°ë¦¬ ì„ í˜¸)
        budget_mid = (user_profile.get('budget_min', 0) + user_profile.get('budget_max', 5000)) / 2
        preferred_year = user_profile.get('min_year', 2018)
        preferred_mileage = 50000  # ê¸°ë³¸ê°’

        numeric_vector = self.scaler.transform([[preferred_year, budget_mid, preferred_mileage]])[0]

        # ë²¡í„° ê²°í•©
        return np.hstack([text_vector, numeric_vector])

class PopularityBasedRecommender:
    """ì¸ê¸°ë„ ê¸°ë°˜ ì¶”ì²œê¸°"""

    def __init__(self):
        self.popularity_scores = {}
        self.trend_weights = {
            'view_count': 0.3,
            'inquiry_count': 0.4,
            'recent_activity': 0.2,
            'price_competitiveness': 0.1
        }

    def calculate_popularity(self, vehicles_df: pd.DataFrame, interaction_data: Optional[pd.DataFrame] = None) -> Dict[int, float]:
        """ì¸ê¸°ë„ ì ìˆ˜ ê³„ì‚°"""
        try:
            popularity_scores = {}

            for idx, vehicle in vehicles_df.iterrows():
                score = 0.0

                # ê¸°ë³¸ ì¸ê¸°ë„ (ë¸Œëœë“œë³„)
                brand_popularity = self._get_brand_popularity(vehicle['brand'])
                score += brand_popularity * 0.3

                # ì—°ì‹ ê¸°ë°˜ ì ìˆ˜
                year_score = self._calculate_year_score(vehicle['year'])
                score += year_score * 0.2

                # ê°€ê²© ê²½ìŸë ¥
                price_score = self._calculate_price_competitiveness(vehicle, vehicles_df)
                score += price_score * 0.3

                # ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ìˆìœ¼ë©´ í™œìš©
                if interaction_data is not None:
                    interaction_score = self._calculate_interaction_score(vehicle['id'], interaction_data)
                    score += interaction_score * 0.2
                else:
                    # ê¸°ë³¸ ì ìˆ˜
                    score += 0.5 * 0.2

                popularity_scores[idx] = min(1.0, max(0.0, score))

            self.popularity_scores = popularity_scores
            logger.info(f"âœ… ì¸ê¸°ë„ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ: {len(popularity_scores)}ëŒ€")
            return popularity_scores

        except Exception as e:
            logger.error(f"âŒ ì¸ê¸°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}

    def _get_brand_popularity(self, brand: str) -> float:
        """ë¸Œëœë“œë³„ ì¸ê¸°ë„"""
        brand_scores = {
            'hyundai': 0.85, 'kia': 0.82, 'genesis': 0.78,
            'toyota': 0.90, 'honda': 0.85, 'nissan': 0.75,
            'bmw': 0.88, 'mercedes': 0.90, 'audi': 0.85,
            'volkswagen': 0.80, 'volvo': 0.75, 'lexus': 0.88
        }
        return brand_scores.get(brand.lower(), 0.6)

    def _calculate_year_score(self, year: int) -> float:
        """ì—°ì‹ ê¸°ë°˜ ì ìˆ˜"""
        current_year = datetime.now().year
        age = current_year - year

        if age <= 2:
            return 1.0
        elif age <= 5:
            return 0.8
        elif age <= 10:
            return 0.6
        else:
            return 0.3

    def _calculate_price_competitiveness(self, vehicle: pd.Series, vehicles_df: pd.DataFrame) -> float:
        """ê°€ê²© ê²½ìŸë ¥ ì ìˆ˜"""
        same_brand_vehicles = vehicles_df[
            (vehicles_df['brand'] == vehicle['brand']) &
            (abs(vehicles_df['year'] - vehicle['year']) <= 2)
        ]

        if len(same_brand_vehicles) < 2:
            return 0.5

        price_percentile = (same_brand_vehicles['price'] <= vehicle['price']).mean()

        # ê°€ê²©ì´ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜ (ì—­ìƒê´€ê´€ê³„)
        return 1.0 - price_percentile

    def _calculate_interaction_score(self, vehicle_id: int, interaction_data: pd.DataFrame) -> float:
        """ìƒí˜¸ì‘ìš© ê¸°ë°˜ ì ìˆ˜"""
        vehicle_interactions = interaction_data[interaction_data['vehicle_id'] == vehicle_id]

        if len(vehicle_interactions) == 0:
            return 0.3

        # ì¡°íšŒìˆ˜, ë¬¸ì˜ìˆ˜, ìµœê·¼ í™œë™ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
        view_score = min(1.0, vehicle_interactions['view_count'].sum() / 100)
        inquiry_score = min(1.0, vehicle_interactions['inquiry_count'].sum() / 10)

        return (view_score * 0.6 + inquiry_score * 0.4)

class HybridRecommendationSystem:
    """í†µí•© í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.content_recommender = ContentBasedRecommender()
        self.popularity_recommender = PopularityBasedRecommender()
        self.ncf_model = None
        self.is_trained = False
        self.executor = ThreadPoolExecutor(max_workers=4)

        # ê°€ì¤‘ì¹˜ ì„¤ì •
        self.weights = {
            'content_based': 0.4,
            'collaborative': 0.3,
            'popularity': 0.3
        }

        logger.info("ğŸ¤– í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    async def train(self, vehicles_df: pd.DataFrame, interaction_data: Optional[pd.DataFrame] = None):
        """ì¶”ì²œ ì‹œìŠ¤í…œ í•™ìŠµ"""
        try:
            logger.info(f"ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œì‹œìŠ¤í…œ í•™ìŠµ ì‹œì‘: {len(vehicles_df)}ëŒ€ ì°¨ëŸ‰")

            # Content-based í•™ìŠµ
            await asyncio.get_event_loop().run_in_executor(
                self.executor, self.content_recommender.fit, vehicles_df
            )

            # Popularity ì ìˆ˜ ê³„ì‚°
            await asyncio.get_event_loop().run_in_executor(
                self.executor, self.popularity_recommender.calculate_popularity, vehicles_df, interaction_data
            )

            # NCF ëª¨ë¸ í•™ìŠµ (ìƒí˜¸ì‘ìš© ë°ì´í„°ê°€ ìˆì„ ë•Œ)
            if interaction_data is not None and len(interaction_data) > 100:
                await self._train_ncf_model(interaction_data, len(vehicles_df))

            self.is_trained = True
            logger.info("âœ… í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œì‹œìŠ¤í…œ í•™ìŠµ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œì‹œìŠ¤í…œ í•™ìŠµ ì‹¤íŒ¨: {e}")
            raise

    async def recommend(self, user_profile: Dict[str, Any], vehicles_df: pd.DataFrame, top_k: int = 10) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹¤í–‰"""
        try:
            if not self.is_trained:
                await self.train(vehicles_df)

            logger.info(f"ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œì‘: ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜")

            # ê° ì¶”ì²œê¸°ì—ì„œ ì ìˆ˜ ê³„ì‚°
            content_scores = await self._get_content_scores(user_profile, len(vehicles_df))
            popularity_scores = await self._get_popularity_scores(len(vehicles_df))
            collaborative_scores = await self._get_collaborative_scores(user_profile, len(vehicles_df))

            # ì ìˆ˜ ê²°í•©
            final_scores = self._combine_scores(content_scores, popularity_scores, collaborative_scores)

            # ìƒìœ„ kê°œ ì„ íƒ
            top_indices = sorted(final_scores.keys(), key=lambda x: final_scores[x], reverse=True)[:top_k]

            # ì¶”ì²œ ê²°ê³¼ ìƒì„±
            recommendations = []
            for idx in top_indices:
                vehicle = vehicles_df.iloc[idx]
                recommendations.append({
                    'vehicle_id': idx,
                    'vehicle_data': vehicle.to_dict(),
                    'score': final_scores[idx],
                    'content_score': content_scores.get(idx, 0.0),
                    'popularity_score': popularity_scores.get(idx, 0.0),
                    'collaborative_score': collaborative_scores.get(idx, 0.0),
                    'reasoning': self._generate_reasoning(vehicle, user_profile)
                })

            logger.info(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì™„ë£Œ: {len(recommendations)}ê°œ ì¶”ì²œ")
            return recommendations

        except Exception as e:
            logger.error(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹¤íŒ¨: {e}")
            return []

    async def _get_content_scores(self, user_profile: Dict[str, Any], num_vehicles: int) -> Dict[int, float]:
        """Content-based ì ìˆ˜ ê³„ì‚°"""
        try:
            recommendations = await asyncio.get_event_loop().run_in_executor(
                self.executor, self.content_recommender.recommend, user_profile, num_vehicles
            )
            return {idx: score for idx, score in recommendations}
        except Exception as e:
            logger.error(f"âŒ Content-based ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}

    async def _get_popularity_scores(self, num_vehicles: int) -> Dict[int, float]:
        """Popularity ì ìˆ˜ ë°˜í™˜"""
        return self.popularity_recommender.popularity_scores

    async def _get_collaborative_scores(self, user_profile: Dict[str, Any], num_vehicles: int) -> Dict[int, float]:
        """Collaborative filtering ì ìˆ˜ ê³„ì‚°"""
        if self.ncf_model is None:
            # NCF ëª¨ë¸ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì ìˆ˜ ë°˜í™˜
            return {i: 0.5 for i in range(num_vehicles)}

        try:
            # NCF ëª¨ë¸ë¡œ ì˜ˆì¸¡ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‚¬ìš©ì ì„ë² ë”© í•„ìš”)
            scores = {}
            user_id = hash(str(user_profile)) % 1000  # ì„ì‹œ ì‚¬ìš©ì ID

            for item_id in range(num_vehicles):
                with torch.no_grad():
                    score = self.ncf_model(
                        torch.tensor([user_id]),
                        torch.tensor([item_id])
                    ).item()
                    scores[item_id] = score

            return scores
        except Exception as e:
            logger.error(f"âŒ Collaborative filtering ì‹¤íŒ¨: {e}")
            return {i: 0.5 for i in range(num_vehicles)}

    def _combine_scores(self, content_scores: Dict[int, float], popularity_scores: Dict[int, float], collaborative_scores: Dict[int, float]) -> Dict[int, float]:
        """ì ìˆ˜ë“¤ì„ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ê²°í•©"""
        all_indices = set(content_scores.keys()) | set(popularity_scores.keys()) | set(collaborative_scores.keys())
        final_scores = {}

        for idx in all_indices:
            content_score = content_scores.get(idx, 0.0)
            popularity_score = popularity_scores.get(idx, 0.0)
            collaborative_score = collaborative_scores.get(idx, 0.0)

            final_score = (
                content_score * self.weights['content_based'] +
                popularity_score * self.weights['popularity'] +
                collaborative_score * self.weights['collaborative']
            )

            final_scores[idx] = final_score

        return final_scores

    def _generate_reasoning(self, vehicle: pd.Series, user_profile: Dict[str, Any]) -> str:
        """ì¶”ì²œ ì´ìœ  ìƒì„±"""
        reasons = []

        # ì˜ˆì‚° ë§¤ì¹­
        budget_min = user_profile.get('budget_min', 0)
        budget_max = user_profile.get('budget_max', float('inf'))
        if budget_min <= vehicle['price'] <= budget_max:
            reasons.append(f"ì˜ˆì‚° ë²”ìœ„ ë‚´ ({vehicle['price']:,}ë§Œì›)")

        # ë¸Œëœë“œ ì„ í˜¸
        preferred_brands = user_profile.get('preferred_brands', [])
        if vehicle['brand'] in preferred_brands:
            reasons.append(f"ì„ í˜¸ ë¸Œëœë“œ ({vehicle['brand']})")

        # ì—°ì‹
        if vehicle['year'] >= user_profile.get('min_year', 2015):
            reasons.append(f"ìµœì‹  ì—°ì‹ ({vehicle['year']}ë…„)")

        return " â€¢ ".join(reasons) if reasons else "ì¢…í•© ë¶„ì„ ê²°ê³¼ ì¶”ì²œ"

    async def _train_ncf_model(self, interaction_data: pd.DataFrame, num_items: int):
        """NCF ëª¨ë¸ í•™ìŠµ"""
        try:
            logger.info("ğŸ¤– NCF ëª¨ë¸ í•™ìŠµ ì‹œì‘...")

            num_users = interaction_data['user_id'].nunique()
            self.ncf_model = NCFModel(num_users, num_items)

            # ê°„ë‹¨í•œ í•™ìŠµ ë£¨í”„ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ í•™ìŠµ í•„ìš”)
            optimizer = optim.Adam(self.ncf_model.parameters(), lr=0.001)
            criterion = nn.BCELoss()

            for epoch in range(10):  # ë¹ ë¥¸ í•™ìŠµì„ ìœ„í•´ 10 ì—í¬í¬ë§Œ
                total_loss = 0
                for _, row in interaction_data.iterrows():
                    user_id = torch.tensor([row['user_id']])
                    item_id = torch.tensor([row['vehicle_id']])
                    rating = torch.tensor([row['rating'] / 5.0])  # 0-1 ì •ê·œí™”

                    prediction = self.ncf_model(user_id, item_id)
                    loss = criterion(prediction, rating.unsqueeze(0))

                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    total_loss += loss.item()

            logger.info("âœ… NCF ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ NCF ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
hybrid_recommender = HybridRecommendationSystem()

async def get_hybrid_recommendations(user_profile: Dict[str, Any], vehicles_df: pd.DataFrame, top_k: int = 10) -> List[Dict[str, Any]]:
    """í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ API"""
    return await hybrid_recommender.recommend(user_profile, vehicles_df, top_k)