import { NextRequest, NextResponse } from 'next/server';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { searchVehicles } from '@/lib/database';

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);

interface ChatRequest {
  question: string;
  context?: string;
}

// ì˜ˆì‚° ì¶”ì¶œ í•¨ìˆ˜
function extractBudget(question: string): { min: number; max: number } {
  const budgetPatterns = [
    /(\d+(?:,\d+)*)\s*ë§Œì›/g,
    /(\d+(?:,\d+)*)\s*ì²œë§Œì›/g,
    /(\d+(?:,\d+)*)\s*ì–µ/g,
    /ì˜ˆì‚°.*?(\d+(?:,\d+)*)/g,
    /(\d+(?:,\d+)*)\s*ì •ë„/g
  ];

  let budgetAmount = 2500; // ê¸°ë³¸ê°’ 2500ë§Œì›

  for (const pattern of budgetPatterns) {
    const matches = question.match(pattern);
    if (matches) {
      const numbers = matches.map(match => {
        const num = match.replace(/[^\d]/g, '');
        return parseInt(num);
      });

      if (numbers.length > 0) {
        budgetAmount = Math.max(...numbers);

        // ì²œë§Œì›, ì–µ ë‹¨ìœ„ ì²˜ë¦¬
        if (question.includes('ì²œë§Œì›')) {
          budgetAmount = budgetAmount * 1000;
        } else if (question.includes('ì–µ')) {
          budgetAmount = budgetAmount * 10000;
        }
        break;
      }
    }
  }

  // ë²”ìœ„ ì„¤ì • (Â±20%)
  const min = Math.max(budgetAmount * 0.8, 1000);
  const max = budgetAmount * 1.2;

  return { min, max };
}

// A2A (Agent-to-Agent) ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
class MultiAgentSystem {
  private genAI: any;

  constructor(apiKey: string) {
    this.genAI = new GoogleGenerativeAI(apiKey);
  }

  // ì»¨ì‹œì–´ì§€ ë§¤ë‹ˆì € - ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸
  async runConciergeManager(question: string, context: string): Promise<string> {
    const model = this.genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

    const prompt = `ë‹¹ì‹ ì€ CarFin AIì˜ ì»¨ì‹œì–´ì§€ ë§¤ë‹ˆì €ë¡œì„œ ì „ì²´ ìƒë‹´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³ , ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ë¥¸ ì „ë¬¸ê°€ë“¤ì—ê²Œ ëª…í™•í•œ ì§€ì‹œë¥¼ ë‚´ë¦¬ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆë¬¸: "${question}"
ìƒí™©: ${context === 'real_ai_analysis' ? 'ì´ˆê¸° ìƒë‹´' : 'ì¶”ê°€ ì§ˆë¬¸'}

ì‘ë‹µ ë°©ì‹:
- ì¹œê·¼í•œ ì¸ì‚¬ì™€ í•¨ê»˜ ìƒë‹´ ê³¼ì •ì„ ê°„ë‹¨íˆ ì•ˆë‚´
- ì§ˆë¬¸ì—ì„œ íŒŒì•…ëœ í•µì‹¬ ìš”êµ¬ì‚¬í•­ì„ ê°„ëµíˆ ìš”ì•½
- ë‹¤ìŒ ë‹¨ê³„(ë‹ˆì¦ˆ ë¶„ì„ â†’ ë°ì´í„° ë¶„ì„) ì˜ˆê³ 

ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(**,##,- ë“±)ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ 5-6ë¬¸ì¥ ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.`;

    const result = await model.generateContent(prompt);
    return await result.response.text();
  }

  // ë‹ˆì¦ˆ ë¶„ì„ ì „ë¬¸ê°€ - ë‘ ë²ˆì§¸ ì—ì´ì „íŠ¸
  async runNeedsAnalyst(question: string, conciergeAnalysis: string): Promise<string> {
    const model = this.genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

    const prompt = `ë‹¹ì‹ ì€ CarFin AIì˜ ë‹ˆì¦ˆ ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ ì‚¬ìš©ìì˜ ìˆ¨ì€ ë‹ˆì¦ˆë¥¼ ì™„ë²½íˆ ë°œêµ´í•˜ê³ , ë¼ì´í”„ìŠ¤íƒ€ì¼ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì°¨ëŸ‰ ì¡°ê±´ì„ ë„ì¶œí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

ì›ë³¸ ì‚¬ìš©ì ì§ˆë¬¸: "${question}"
ì»¨ì‹œì–´ì§€ ë§¤ë‹ˆì € ë¶„ì„: "${conciergeAnalysis}"

ë¶„ì„ ì˜ì—­:
- ì‚¬ìš©ìê°€ ëª…ì‹œí•˜ì§€ ì•Šì€ ìˆ¨ì€ ë‹ˆì¦ˆ ë°œêµ´
- ë¼ì´í”„ìŠ¤íƒ€ì¼ íŒ¨í„´ ë¶„ì„ (í†µê·¼, ê°€ì¡±, ì·¨ë¯¸, ê²½ì œìƒí™© ë“±)
- ìš°ì„ ìˆœìœ„ ë„ì¶œ (ì•ˆì „ì„±, ê²½ì œì„±, í¸ì˜ì„±, ì„±ëŠ¥ ë“±)

ì‘ë‹µ ë‚´ìš©:
- ë°œêµ´ëœ ì£¼ìš” ë‹ˆì¦ˆë“¤ê³¼ ê·¸ ê·¼ê±°ë¥¼ ê°„ëµíˆ ì„¤ëª…
- ì¶”ì²œí•˜ëŠ” ì°¨ëŸ‰ íƒ€ì…ê³¼ í•µì‹¬ ì¡°ê±´ë“¤

ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(**,##,- ë“±)ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ 7-8ë¬¸ì¥ ë‚´ì™¸ë¡œ ë‹µë³€í•˜ì„¸ìš”.`;

    const result = await model.generateContent(prompt);
    return await result.response.text();
  }

  // ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ - ì„¸ ë²ˆì§¸ ì—ì´ì „íŠ¸
  async runDataAnalyst(question: string, conciergeAnalysis: string, needsAnalysis: string, vehicleData: any[]): Promise<string> {
    const model = this.genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

    const prompt = `ë‹¹ì‹ ì€ CarFin AIì˜ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ ì‹¤ì œ ì°¨ëŸ‰ ë§¤ë¬¼ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì²´ì ì¸ ì¶”ì²œê³¼ TCO(ì´ì†Œìœ ë¹„ìš©) ë¶„ì„ì„ ì œê³µí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

ì›ë³¸ ì‚¬ìš©ì ì§ˆë¬¸: "${question}"
ì»¨ì‹œì–´ì§€ ë§¤ë‹ˆì € ë¶„ì„: "${conciergeAnalysis}"
ë‹ˆì¦ˆ ë¶„ì„ ì „ë¬¸ê°€ ë¶„ì„: "${needsAnalysis}"

ì‹¤ì œ ì°¨ëŸ‰ ë°ì´í„° (ì´ ${vehicleData.length}ëŒ€):
${vehicleData.map((v, i) => `${i+1}. ${v.manufacturer} ${v.model} ${v.modelyear}ë…„ - ${v.price?.toLocaleString()}ë§Œì› (${v.distance?.toLocaleString()}km) ${v.location} [ì—°ë£Œ: ${v.fueltype}]`).join('\n')}

ë¶„ì„ ì˜ì—­:
- ìœ„ ì‹¤ì œ ë§¤ë¬¼ ì¤‘ì—ì„œ ìµœì  ì¶”ì²œ ì°¨ëŸ‰ ì„ ë³„
- TCO ë¶„ì„ (êµ¬ë§¤ê°€ê²© + ìœ ì§€ë¹„ + ê°ê°€ìƒê° + ë³´í—˜ë£Œ ë“±)
- ê° ì¶”ì²œ ì°¨ëŸ‰ì˜ ì¥ë‹¨ì  ë¹„êµ ë¶„ì„
- êµ¬ë§¤ í›„ ì˜ˆìƒë˜ëŠ” ì‹¤ì œ ë¹„ìš©ê³¼ ë§Œì¡±ë„ ì˜ˆì¸¡

ì‘ë‹µ ë‚´ìš©:
- ì¶”ì²œ ì°¨ëŸ‰ 2-3ëŒ€ì™€ êµ¬ì²´ì  ì„ ì • ì´ìœ 
- ê° ì°¨ëŸ‰ì˜ ì˜ˆìƒ TCOì™€ ê²½ì œì„± ë¶„ì„ì„ ê°„ë‹¨íˆ
- ì‹¤ìš©ì ì¸ êµ¬ë§¤ ì¡°ì–¸

ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(**,##,- ë“±)ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ 8-10ë¬¸ì¥ ë‚´ì™¸ë¡œ ë‹µë³€í•˜ì„¸ìš”.`;

    const result = await model.generateContent(prompt);
    return await result.response.text();
  }

  // A2A í˜‘ì—… ì‹¤í–‰ - 3ëª… ì—ì´ì „íŠ¸ ìˆœì°¨ í˜‘ì—…
  async executeA2ACollaboration(question: string, context: string, vehicleData: any[]): Promise<any> {
    console.log('ğŸš€ A2A ë©€í‹°ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œì‘');

    // 1ë‹¨ê³„: ì»¨ì‹œì–´ì§€ ë§¤ë‹ˆì € ë¶„ì„
    console.log('1ï¸âƒ£ ì»¨ì‹œì–´ì§€ ë§¤ë‹ˆì € ë¶„ì„ ì¤‘...');
    const conciergeAnalysis = await this.runConciergeManager(question, context);

    // 2ë‹¨ê³„: ë‹ˆì¦ˆ ë¶„ì„ ì „ë¬¸ê°€ ë¶„ì„ (ì»¨ì‹œì–´ì§€ ê²°ê³¼ í™œìš©)
    console.log('2ï¸âƒ£ ë‹ˆì¦ˆ ë¶„ì„ ì „ë¬¸ê°€ ë¶„ì„ ì¤‘...');
    const needsAnalysis = await this.runNeedsAnalyst(question, conciergeAnalysis);

    // 3ë‹¨ê³„: ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ ë¶„ì„ (ì´ì „ ê²°ê³¼ë“¤ í™œìš©)
    console.log('3ï¸âƒ£ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ ë¶„ì„ ì¤‘...');
    const dataAnalysis = await this.runDataAnalyst(question, conciergeAnalysis, needsAnalysis, vehicleData);

    return {
      conciergeAnalysis,
      needsAnalysis,
      dataAnalysis,
      collaborationComplete: true
    };
  }
}

export async function POST(request: NextRequest) {
  try {
    const { question, context }: ChatRequest = await request.json();

    if (!question) {
      return NextResponse.json({
        success: false,
        error: 'Question is required'
      }, { status: 400 });
    }

    console.log(`ğŸš€ Real A2A Analysis Started: "${question}" [${context}]`);

    // ì‹¤ì œ ì°¨ëŸ‰ ë°ì´í„° ê²€ìƒ‰
    const budget = extractBudget(question);
    const vehicles = await searchVehicles(budget);

    console.log(`ğŸ’° Budget: ${budget.min}-${budget.max}ë§Œì›`);
    console.log(`ğŸš— Found ${vehicles.length} real vehicles from PostgreSQL`);

    // A2A ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    const multiAgentSystem = new MultiAgentSystem(process.env.GEMINI_API_KEY!);

    // ì‹¤ì œ 3-Agent í˜‘ì—… ì‹¤í–‰ (Mock ì—†ìŒ!)
    const collaboration = await multiAgentSystem.executeA2ACollaboration(question, context || 'real_ai_analysis', vehicles);

    console.log('âœ… A2A í˜‘ì—… ì™„ë£Œ');

    // ì²« ë²ˆì§¸ ì‘ë‹µìœ¼ë¡œëŠ” ì»¨ì‹œì–´ì§€ ë§¤ë‹ˆì € ê²°ê³¼ ë°˜í™˜
    // TODO: ë‚˜ì¤‘ì— WebSocketìœ¼ë¡œ ê° ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
    return NextResponse.json({
      success: true,
      response: collaboration.conciergeAnalysis, // ì²« ì‘ë‹µì€ ì»¨ì‹œì–´ì§€ ë§¤ë‹ˆì €
      agentType: 'concierge',
      metadata: {
        budget: budget,
        vehiclesFound: vehicles.length,
        model: 'gemini-2.5-flash',
        collaborationId: `collab-${Date.now()}`,
        timestamp: new Date().toISOString(),
        a2aEnabled: true,
        mockDataUsed: false, // ì¤‘ìš”: Mock ë°ì´í„° ì‚¬ìš© ì•ˆí•¨
        // ë‚˜ë¨¸ì§€ ì—ì´ì „íŠ¸ ê²°ê³¼ë“¤ (ë‚˜ì¤‘ì— WebSocketìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì˜ˆì •)
        pendingAgents: {
          needsAnalysis: collaboration.needsAnalysis,
          dataAnalysis: collaboration.dataAnalysis
        }
      }
    });

  } catch (error) {
    console.error('ğŸš¨ Real AI Analysis Error:', error);

    return NextResponse.json({
      success: false,
      error: 'Real AI analysis failed',
      details: error instanceof Error ? error.message : 'Unknown error',
      mockDataUsed: false
    }, { status: 500 });
  }
}